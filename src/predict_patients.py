import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import pandas as pd
import os
import glob
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm

# ==========================================
# 1. æ ¸å¿ƒè·¯å¾„é…ç½®
# ==========================================
MODEL_PATH = "/import2/hhome/ricse05/Deep-Learning-P1/runs/resnet18_seed42/best.pth"
PATIENT_CSV = "/fhome/vlia/HelicoDataSet/PatientDiagnosis.csv"
IMG_ROOT = "/fhome/vlia/HelicoDataSet"

# âš ï¸ Phase 2 æ”¹åŠ¨ï¼šåªæ‰«æ Croppedï¼Œå®Œå…¨ä¸ç¢° HoldOut
SEARCH_DIRS = ["CrossValidation/Cropped"]

OUTPUT_CSV = "cropped_patient_diagnosis_report.csv"  # è¾“å‡ºæ–‡ä»¶åä¹Ÿæ”¹äº†ï¼Œé¿å…è¦†ç›–æ—§ç»“æœ

# ==========================================
# 2. å›¾åƒé¢„å¤„ç†ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
# ==========================================
preprocess = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

class FastInferenceDataset(Dataset):
    def __init__(self, img_paths):
        self.img_paths = img_paths
    def __len__(self):
        return len(self.img_paths)
    def __getitem__(self, idx):
        try:
            img = Image.open(self.img_paths[idx]).convert('RGB')
            return preprocess(img)
        except Exception:
            return torch.zeros(3, 256, 256)

def run_inference():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ æ­£åœ¨ä½¿ç”¨è®¾å¤‡: {device}")

    # ------------------------------------------
    # 3. åŠ è½½æ¨¡å‹
    # ------------------------------------------
    print(f"ğŸ“¦ åŠ è½½æƒé‡æ–‡ä»¶: {MODEL_PATH}")
    model = models.resnet18(weights=None)
    model.fc = nn.Linear(model.fc.in_features, 2)

    checkpoint = torch.load(MODEL_PATH, map_location=device, weights_only=False)
    if isinstance(checkpoint, dict) and 'model_state' in checkpoint:
        print("ğŸ’¡ æ£€æµ‹åˆ°å¤§ç¤¼åŒ…æ ¼å¼ï¼Œæ­£åœ¨æå– model_state...")
        model.load_state_dict(checkpoint['model_state'])
    else:
        print("ğŸ’¡ æ£€æµ‹åˆ°ç›´æ¥æƒé‡æ ¼å¼ï¼Œæ­£åœ¨åŠ è½½...")
        model.load_state_dict(checkpoint)

    model = model.to(device)
    model.eval()

    # ------------------------------------------
    # 4. å‡†å¤‡ç—…äººåå•ï¼ˆåªå¤„ç†èƒ½åœ¨ Cropped é‡Œæ‰¾åˆ°å›¾ç‰‡çš„ç—…äººï¼‰
    # ------------------------------------------
    patient_df = pd.read_csv(PATIENT_CSV)
    final_report = []
    skipped = 0

    print(f"ğŸ” å¼€å§‹ä¸º {len(patient_df)} ä½ç—…äººæ‰«æ Cropped æ–‡ä»¶å¤¹...")
    print(f"âš ï¸  æ³¨æ„ï¼šHoldOut æ–‡ä»¶å¤¹åœ¨æœ¬é˜¶æ®µå®Œå…¨è·³è¿‡ï¼Œç•™ç»™ Phase 4 ç›²æµ‹ã€‚\n")

    for _, row in tqdm(patient_df.iterrows(), total=len(patient_df), desc="æ¨ç†è¿›åº¦"):
        codi = str(row['CODI'])

        # åªåœ¨ Cropped é‡Œæ‰¾ç—…äººæ–‡ä»¶å¤¹
        patient_folder = None
        for d in SEARCH_DIRS:
            matches = glob.glob(os.path.join(IMG_ROOT, d, f"{codi}_*"))
            if matches:
                patient_folder = matches[0]
                break

        if not patient_folder:
            skipped += 1
            continue  # ä¸åœ¨ Cropped é‡Œçš„ç—…äººï¼ˆå³ HoldOut ç—…äººï¼‰ç›´æ¥è·³è¿‡

        all_imgs = glob.glob(os.path.join(patient_folder, "*.png"))
        if not all_imgs:
            skipped += 1
            continue

        # ------------------------------------------
        # 5. æ‰¹é‡æ¨ç†è¯¥ç—…äººçš„æ‰€æœ‰åˆ‡ç‰‡
        # ------------------------------------------
        ds = FastInferenceDataset(all_imgs)
        dl = DataLoader(ds, batch_size=128, num_workers=4, pin_memory=True)

        pos_count = 0
        with torch.no_grad():
            for batch_imgs in dl:
                batch_imgs = batch_imgs.to(device)
                outputs = model(batch_imgs)
                preds = torch.max(outputs, 1)[1]
                pos_count += torch.sum(preds == 1).item()

        final_report.append({
            'Pat_ID': codi,
            'Doctor_Diagnosis': row['DENSITAT'],
            'Total_Patches': len(all_imgs),
            'Model_Positive_Count': pos_count,
            'Positive_Ratio': pos_count / len(all_imgs),
            'Source': 'Cropped'  # æ–°å¢å­—æ®µï¼Œæ–¹ä¾¿åç»­è¿½è¸ªæ•°æ®æ¥æº
        })

    # ------------------------------------------
    # 6. ä¿å­˜ç»“æœ
    # ------------------------------------------
    report_df = pd.DataFrame(final_report)
    report_df.to_csv(OUTPUT_CSV, index=False)

    print(f"\n" + "="*55)
    print(f"âœ… Phase 2 æ¨ç†å®Œæˆï¼ˆä»… Croppedï¼‰")
    print(f"ğŸ“Š æˆåŠŸæ¨ç†ç—…äººæ•°: {len(final_report)}")
    print(f"â­ï¸  è·³è¿‡ç—…äººæ•°ï¼ˆä¸åœ¨ Cropped / æ— å›¾ç‰‡ï¼‰: {skipped}")
    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {OUTPUT_CSV}")
    print(f"â¡ï¸  ä¸‹ä¸€æ­¥ï¼šè¿è¡Œ analyze_results.py å¯»æ‰¾æœ€ä¼˜é˜ˆå€¼")
    print("="*55)

if __name__ == "__main__":
    run_inference()