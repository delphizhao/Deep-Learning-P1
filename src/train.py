import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from torchvision import transforms, models
import os
from dataset import HPyloriDataset


def main():
    print("--- ğŸ”¬ å¹½é—¨èºæ†èŒ AI è®­ç»ƒ+éªŒè¯æ¨¡å¼å¯åŠ¨ ---")

    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    excel_path = os.path.join(base_dir, 'data', 'HP_WSI-CoordAnnotatedAllPatches.xlsx')
    img_dir = os.path.join(base_dir, 'data', 'images')

    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    # 1. åŠ è½½å…¨é‡æ•°æ®é›†
    full_dataset = HPyloriDataset(excel_path, img_dir, transform=transform, local_debug=True)

    # 2. åˆ’åˆ†æ•°æ®é›† (80% è®­ç»ƒ, 20% éªŒè¯)
    train_size = int(0.8 * len(full_dataset))
    val_size = len(full_dataset) - train_size
    # æ³¨æ„ï¼šæœ¬åœ°åªæœ‰5å¼ å›¾æ—¶ï¼Œtrainå¯èƒ½4å¼ ï¼Œvalå¯èƒ½1å¼ 
    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)

    print(f"ğŸ“Š åˆ’åˆ†å®Œæˆ: è®­ç»ƒé›† {len(train_dataset)} å¼ , éªŒè¯é›† {len(val_dataset)} å¼ ")

    # 3. åˆå§‹åŒ–æ¨¡å‹
    model = models.resnet18(weights='DEFAULT')
    model.fc = nn.Linear(model.fc.in_features, 2)

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.0001)

    # 4. è®­ç»ƒå¾ªç¯
    for epoch in range(5):
        # --- è®­ç»ƒé˜¶æ®µ ---
        model.train()
        train_loss = 0.0
        for images, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()

        # --- éªŒè¯é˜¶æ®µ (è¿™å°±æ˜¯ä½ è¦çš„æ­¥éª¤) ---
        model.eval()  # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼
        correct = 0
        total = 0
        with torch.no_grad():  # è€ƒè¯•æ—¶ä¸éœ€è¦è®°å½•æ¢¯åº¦ï¼ŒèŠ‚çœå†…å­˜
            for images, labels in val_loader:
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        accuracy = 100 * correct / total
        print(f"Epoch [{epoch + 1}/5] | è®­ç»ƒ Loss: {train_loss / len(train_loader):.4f} | éªŒè¯å‡†ç¡®ç‡: {accuracy:.2f}%")

    print("\nğŸ‰ è®­ç»ƒä¸éªŒè¯é€»è¾‘æµ‹è¯•å®Œæˆï¼")


if __name__ == '__main__':
    main()